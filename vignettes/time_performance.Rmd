---
title: "performance"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{performance}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


# Introduction

Sometimes processing images is computtionally expensive, more noticeably ... 
slow, this vignette tries to show the ways in which image processing can be
accelerated.

```{r setup}
library(clasifierrr)
library(EBImage)
```

We will start with the same files as the ones in the readme

```{r}
params_df <- tibble::tibble(
    file = c(
        system.file(
            "extdata", "tiny_4T1-shNT-1_layer1.png",
            package = "clasifierrr"),
        system.file(
            "extdata", "tiny_4T1-shNT-1_layer2.png",
            package = "clasifierrr")),
    classif = c("spheroid", "bg"),
    related_file = system.file(
        "extdata", "tiny_4T1-shNT-1.png",
        package = "clasifierrr")
)

params_df
```

```{r}
base_image <- readImageBw(params_df[[3]][[1]])
display(base_image, method = "raster")
```

# Image Pre-processing

```{r}
time_taken_full <- system.time({
    features <- calc_features(
        base_image, 
        filter_widths = c(3,5), shape_sizes = c(51, 101))
})

time_taken_full
object.size(features)
```

we can notice that it takes `r time_taken_full[[3]]` 
seconds to achieve the calculation and the `features`
object ocupies 
`r format(object.size(features), units = "Mb")`.

Nonetheless, since we basically are doing one calculation
per pixels, per filter, decreasing the number of pixels would
decrease the number of calculation by that number. 
And therefore, decreasing the size will accelerate the speed
with the square of that reduction (since its a 2d image)

```{r}
newsize <- as.integer(ncol(base_image)/2)
shrunk_image <- resize(base_image, w = newsize)

time_taken_shrunk <- system.time({
    shrunk_features <- calc_features(
        shrunk_image, 
        filter_widths = c(3,5), shape_sizes = c(15, 31))
})

time_taken_shrunk
object.size(shrunk_features)
```


we can notice that now it takes `r time_taken_shrunk[[3]]` 
seconds to achieve the calculation and the `shrunk_features`
object ocupies 
`r format(object.size(shrunk_features), units = "Mb")`.

which is a `r time_taken_full[[3]]/time_taken_shrunk[[3]]`
fold decrease in time and 
`r object.size(features)/object.size(shrunk_features)`
decrease in used memmory

lets take a look at the actual filters ...


```{r}
display_filters(shrunk_features, dim(shrunk_image), scale = TRUE)
display_filters(features, dim(base_image), scale = TRUE)
```

Note how, since the filter sizes are still the same,
but the image size is different, the filters have slightly
different effects.

now ... I have implemented a way to make this automatic
for the multiple case set.

For that you need to write a function that does the 
processing you want and pass it as an argument to 
`preprocess_fun_img` and `preprocess_fun_mask`

```{r}
half_image <- function(x) {
    newsize <- as.integer(ncol(x)/2)
    shrunk_image <- resize(x, w = newsize)
    return(shrunk_image)
}
```


```{r}
multi_time_full <- system.time({
    trainset <- build_train_multi(
        params_df, 
        train_size_each = 5000, 
        filter_widths = c(3,5))
})

multi_time_shrunk <- system.time({
    trainset <- build_train_multi(
        params_df, 
        preprocess_fun_img = half_image,
        preprocess_fun_mask = half_image, 
        train_size_each = 5000, 
        filter_widths = c(3,5), shape_sizes = c(15, 31))
})

multi_time_full
multi_time_shrunk
head(trainset)
```

In this case it would be a increase in `r multi_time_full[[3]]/multi_time_shrunk[[3]]` 
times of computation.


Preprocessing functions can be much more complicated ...


```{r}
preprocess_img <- function(x) {
    x <- correct_light(x, chunk_width = 11)
    x <- half_image(x)
    x <- x - min(min(x), 0)
    x <- x/max(x)
    return(x)
}

preprocessed_image <- preprocess_img(base_image)
display(base_image, method = "raster")
display(preprocessed_image, method = "raster")
```


```{r}
multi_time_shrunk <- system.time({
    trainset_preproc <- build_train_multi(
        params_df, 
        preprocess_fun_img = preprocess_img,
        preprocess_fun_mask = half_image, 
        train_size_each = 1000, 
        filter_widths = c(3,5),
        shape_sizes = c(15, 31))
})
```

# Precompilation of filters

This section does not address per-se accelerating things but re-using sections
of the functions when processing many images.

```{r}
system.time({
for (i in 1:10) {
  features <- calc_features(
    base_image, 
    filter_widths = c(3,5,7,11,15),
    shape_sizes = c(15, 31))
}})

fft_image <- fftwtools::fftw2d(base_image)
precompiled_filters <- compile_calc_features(
  c(3,5,7,11,15),
  shape_sizes = c(15, 31),
  dim(base_image))

system.time({
for (i in 1:10) {
  features <- purrr::map_dfc(precompiled_filters, ~ as.numeric(.x(fft_image)))
}})

```

Internally what happens is that, each image gets converted to fourer space, the 
filter is expanded to the size of the image and converted to fourier space. 
Multiplied (in fourier space) and the product of the two of them is then 
converted back to normal space.

Converting to fourier space is expensive, but if every filter will use the same
converted image, that can be calculated once and saved. In the same way, if a 
filter will be used many times (on images the same size), it can be calculated
and used many times.

# Parallel processing

Some of the internals of the functions that calculate many filters are based on
the `future` package, which allows one to run them in parallel.

```{r}
require(future)
plan(multiprocess, workers = 2)

features <- calc_features(
  base_image, 
  filter_widths = c(3,5,7,11,15),
  shape_sizes = c(15, 31))

```

